ğŸ§  Memoric

Policy-driven, deterministic memory framework for AI agents

â€œMemoric gives your AI agents structured, explainable, and persistent memory â€” without the black box.â€

ğŸ“– Overview

Memoric is an open-source Python framework that provides a robust, deterministic memory layer for AI agents.
It helps AI teams deploy agents with long-term, rule-based memory, structured by metadata, organized by tiers, and retrievable through policy-driven scoring.

Instead of relying solely on vector embeddings or opaque similarity searches, Memoric focuses on structure, transparency, and control.
Every stored memory is traceable, explainable, and policy-governed â€” enabling predictable, high-relevance recall for any AI system.

âœ¨ Key Features

âœ… Deterministic, Rule-Based Retrieval
Retrieve memories using metadata, recency, and importance â€” not fuzzy vector magic.

âœ… Multi-Tier Memory Architecture
Short-term, mid-term, and long-term tiers evolve your memory over time automatically.

âœ… Multi-Threaded Memory Isolation
Maintain separate memory threads (e.g., different chat topics) under one user while preserving cross-thread relevance when needed.

âœ… Metadata Enrichment via Metadata Agent
AI-powered metadata extraction (topics, categories, entities, and importance).

âœ… Policy-Driven YAML Configuration
Define memory rules, expiry, routing, and scoring in one clean YAML file.

âœ… PostgreSQL Backend
Proven, efficient, and enterprise-grade â€” with ready-to-use schemas and indexes.

âœ… Clustered Long-Term Summaries
Automatically condense repeated information into structured knowledge clusters.

âœ… Framework-Agnostic Integration
Works with LangChain, LlamaIndex, or any custom LLM pipeline.

ğŸ§© Core Architecture
User or AI Agent
   â†“
Metadata Agent (adds metadata)
   â†“
Memory Router (applies tier & thread policies)
   â†“
PostgreSQL Memory Store
   â†“
Retriever + Scorer (finds relevant memories)
   â†“
Context Assembler (returns structured context)
   â†“
LLM / Agent


Each layer is modular, configurable, and easy to extend.

ğŸ§± Installation
pip install memoric


(Coming soon â€” currently in early development stage.)

âš™ï¸ Quick Start
1ï¸âƒ£ Create a Config File (config.yaml)
database:
  engine: postgres
  host: localhost
  user: memoric
  password: secret
  db: memoric_db

metadata_agent:
  model: gpt-4o-mini
  extract_fields: [topic, category, entities, sentiment, importance]

tiers:
  short_term:
    expiry_days: 7
  mid_term:
    expiry_days: 90
    trim: true
  long_term:
    expiry_days: 365
    cluster_by: ["topic", "entities"]

retrieval:
  scope: thread  # options: thread | topic | user | global
  fallback: topic
  scoring:
    importance: 0.6
    recency: 0.3
    repetition: 0.1

2ï¸âƒ£ Initialize Memoric
from memoric import Memoric

mem = Memoric(config_path="config.yaml")

3ï¸âƒ£ Store a New Memory
mem.save(
    user_id="U-123",
    thread_id="T-Refunds",
    session_id="S-456",
    message="I still havenâ€™t received my refund for order #1049.",
    role="user"
)


Memoric automatically:

Enriches the message with metadata via the Metadata Agent

Routes it to the appropriate tier (e.g., short_term)

Stores it in PostgreSQL with all relevant metadata

4ï¸âƒ£ Retrieve Context
context = mem.retrieve(
    user_id="U-123",
    thread_id="T-Refunds",
    query="refund status",
    max_results=10
)

print(context)


Example output:

{
  "thread_context": [
    "User: I still havenâ€™t received my refund for order #1049.",
    "Agent: Weâ€™ve escalated your case to finance.",
    "User: Itâ€™s been two weeks now, any updates?"
  ],
  "related_history": [
    "User had similar refund issues in Jan 2024 (Order #1082)."
  ],
  "metadata": {
    "topic": "refunds",
    "category": "customer_support",
    "importance": "high",
    "thread_id": "T-Refunds",
    "user_id": "U-123"
  }
}


This JSON can be injected directly into your LLMâ€™s context window.

ğŸ§  Multi-Tier Memory System

Memoric organizes memories into tiers, each with its own lifecycle and transformation rules.

Tier	Lifetime	Behavior	Purpose
short_term	Days	Raw, recent data	Immediate recall
mid_term	Weeksâ€“Months	Trimmed, compact	Ongoing relevance
long_term	Monthsâ€“Years	Clustered, summarized	Historical continuity

Example evolution:

Day 1   â†’ Stored in short_term  
Day 8   â†’ Moves to mid_term (trimmed)  
Day 100 â†’ Moves to long_term (clustered by topic)


Tier transitions are deterministic and follow your YAML policy.

ğŸ§µ Threaded Memory and Context Isolation

Memoric natively supports multi-threaded memory â€” ideal for agents that handle multiple topics or chat sessions with the same user.

ğŸ§© How It Works

Each message includes a thread_id, letting Memoric isolate and retrieve context per thread while optionally pulling related memories when relevant.

Example:

User 123
 â”œâ”€â”€ Thread: Refunds
 â”‚    â”œâ”€â”€ Message 1
 â”‚    â”œâ”€â”€ Message 2
 â”œâ”€â”€ Thread: Shipping
 â”‚    â”œâ”€â”€ Message 1
 â”‚    â”œâ”€â”€ Message 2


Retrieving refund-related context will only fetch messages from that thread unless your retrieval policy allows topic-based fallback.

ğŸ§© YAML Policy
retrieval:
  scope: thread      # Restrict to the active thread
  fallback: topic    # Fall back to similar-topic history if needed

ğŸ§© Advanced Thread Management
Feature	Description
Thread Isolation	Each conversation thread has its own memory timeline
Thread Linking	Link threads with related topics or entities
Cross-Thread Recall	Optionally fetch related past experiences
Hierarchical Threads	Nested or related threads (e.g., â€œRefund #1049â€ related to â€œRefund #1082â€)
Thread Summarization	Old threads are summarized and stored in long-term memory
Concurrent Thread Safety	PostgreSQL ensures thread-safe writes for multi-agent use
ğŸ§© Example Usage
# Save messages in different threads
mem.save(user_id="U-123", thread_id="T-Refunds", message="Still no refund yet.")
mem.save(user_id="U-123", thread_id="T-Shipping", message="When will my package arrive?")

# Retrieve thread-specific memory
refund_context = mem.retrieve(user_id="U-123", thread_id="T-Refunds")
shipping_context = mem.retrieve(user_id="U-123", thread_id="T-Shipping")


Each retrieval yields isolated thread context plus optional related context via metadata-based linking.

ğŸ§® Scoring System

Each memory (or cluster) is ranked deterministically:

score = (importance * 0.6) + (recency * 0.3) + (repetition * 0.1)


Weights and formulas are fully configurable.

ğŸ§° Developer API
Method	Description
mem.save()	Store a message or event
mem.retrieve()	Retrieve relevant context
mem.run_policies()	Execute tier transitions
mem.add_metadata_agent()	Register or override metadata model
mem.inspect()	Debug memory tiers and scoring
mem.promote_tier()	Manually promote memories between tiers
ğŸ”Œ Integration with AI Frameworks

Memoric works as a universal memory backend for any AI framework.

Example: LangChain Integration
from memoric import MemoricMemory
from langchain.agents import AgentExecutor

memory = MemoricMemory(config_path="config.yaml")

agent = AgentExecutor(
    model="gpt-4o",
    memory=memory
)


Now your LangChain agent benefits from:

Structured, tiered memory

Thread-aware context recall

Explainable, rule-based memory evolution

ğŸ§© Example Database Schema
CREATE TABLE memories (
    id SERIAL PRIMARY KEY,
    user_id TEXT,
    thread_id TEXT,
    session_id TEXT,
    content TEXT,
    metadata JSONB,
    tier TEXT DEFAULT 'short_term',
    importance_score FLOAT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE clusters (
    id SERIAL PRIMARY KEY,
    topic TEXT,
    entities JSONB,
    summary TEXT,
    occurrences INT,
    first_seen TIMESTAMP,
    last_seen TIMESTAMP
);

ğŸ§  Design Philosophy
Principle	Description
Deterministic by default	Every action is explainable and repeatable
Metadata-first design	Structure and clarity before embeddings
Policy-driven logic	YAML-defined behavior for full transparency
Simple, Composable Python	Modular imports, no bloat
Thread-safe and scalable	Built on PostgreSQL transactions
ğŸ¤ Contributing

We welcome contributions from AI engineers, researchers, and open-source developers.

Fork the repo

Create a feature branch (git checkout -b feature/new-idea)

Commit your changes

Submit a PR

Follow the existing structure and commit conventions.

ğŸ›¡ï¸ License

Apache 2.0 â€” free for personal, commercial, and research use.

ğŸ‘¥ Maintainers

Built with â¤ï¸ by Muthanna Al-Faris and contributors.
Part of Nuzum Technologiesâ€™ initiative to build open, explainable AI infrastructure.

ğŸš€ Tagline

Memoric â€” Bring structure, persistence, and reasoning to your AIâ€™s memory.